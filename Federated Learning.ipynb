{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cedba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import scipy.stats\n",
    "from itertools import islice\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9caa2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml(name='mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9905ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_images = len(mnist.data.values)\n",
    "all_images = mnist.data.values\n",
    "all_labels = np.array(list(map(int, mnist.target.values)))\n",
    "all_images = all_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739fef58",
   "metadata": {},
   "source": [
    "### Create clients with uneven class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset without shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_images, all_labels, test_size=0.3, shuffle=True, random_state=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2500b7",
   "metadata": {},
   "source": [
    "## Create clients with even distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd76539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    }
   ],
   "source": [
    "distribution = [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]\n",
    "clients = create_clients(X_train, y_train, distribution)\n",
    "#plot_client_data(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfa711",
   "metadata": {},
   "source": [
    "## Train Clients Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f27b9a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr_cycles = 0\n",
    "\n",
    "while nr_cycles < 40:\n",
    "    for client in clients:\n",
    "        fit_model_to_data(client.model, client.data, client.labels, n_classes=10, epochs=2)\n",
    "    nr_cycles += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a7f46",
   "metadata": {},
   "source": [
    "## Federated Learning Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5791ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  1  complete. Global model accuracy: 0.9390023594858363\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  2  complete. Global model accuracy: 0.9630327515530116\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  3  complete. Global model accuracy: 0.9687151481600054\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  4  complete. Global model accuracy: 0.972371244901408\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  5  complete. Global model accuracy: 0.9743610367917538\n",
      "657/657 [==============================] - 1s 2ms/step\n",
      "Cycle  6  complete. Global model accuracy: 0.9760370577577574\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  7  complete. Global model accuracy: 0.9778896749638151\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  8  complete. Global model accuracy: 0.9786127346195561\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  9  complete. Global model accuracy: 0.9790854221334874\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  10  complete. Global model accuracy: 0.9796523549796179\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  11  complete. Global model accuracy: 0.9801385526045032\n",
      "657/657 [==============================] - 1s 2ms/step\n",
      "Cycle  12  complete. Global model accuracy: 0.9807075511931114\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  13  complete. Global model accuracy: 0.9809919903482788\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  14  complete. Global model accuracy: 0.9806596685579072\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  15  complete. Global model accuracy: 0.9803727123951217\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  16  complete. Global model accuracy: 0.9813259780501161\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  17  complete. Global model accuracy: 0.9811842522635397\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  18  complete. Global model accuracy: 0.9813272812839995\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  19  complete. Global model accuracy: 0.982043032860188\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  20  complete. Global model accuracy: 0.9821394679856752\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  21  complete. Global model accuracy: 0.9818031252205331\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  22  complete. Global model accuracy: 0.9821871785531883\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  23  complete. Global model accuracy: 0.9824701144976463\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  24  complete. Global model accuracy: 0.9817572849758988\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  25  complete. Global model accuracy: 0.9822809405684337\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  26  complete. Global model accuracy: 0.9820908690084039\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  27  complete. Global model accuracy: 0.98237777225009\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  28  complete. Global model accuracy: 0.9822331704357224\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  29  complete. Global model accuracy: 0.9812362235673101\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  30  complete. Global model accuracy: 0.9821872175066712\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  31  complete. Global model accuracy: 0.9825212595663874\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  32  complete. Global model accuracy: 0.9823766586541786\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  33  complete. Global model accuracy: 0.9823298041803102\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  34  complete. Global model accuracy: 0.9824260014944384\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  35  complete. Global model accuracy: 0.9827134782628215\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  36  complete. Global model accuracy: 0.9823774479898431\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  37  complete. Global model accuracy: 0.982281332172313\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  38  complete. Global model accuracy: 0.9823777514541294\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  39  complete. Global model accuracy: 0.9822819935923759\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "Cycle  40  complete. Global model accuracy: 0.9822823614915515\n"
     ]
    }
   ],
   "source": [
    "# Create global model\n",
    "global_model = create_simple_model()\n",
    "\n",
    "global_amount_data = len(X_train)\n",
    "\n",
    "nr_cycles = 0\n",
    "\n",
    "while nr_cycles < 40:\n",
    "    \n",
    "    # Extract weights from global model\n",
    "    global_weights = global_model.get_weights()\n",
    "\n",
    "    # Simulating sending the global model to the clients\n",
    "    for c in clients: \n",
    "        client_model = c.model\n",
    "        client_model.set_weights(global_weights)\n",
    "\n",
    "    # Train clients on their own data\n",
    "    for client in clients:\n",
    "        fit_model_to_data(\n",
    "            client.model, \n",
    "            client.data, \n",
    "            client.labels, \n",
    "            n_classes=10, \n",
    "            epochs=2\n",
    "        )\n",
    "\n",
    "    # Simulate the clients sending their weights to central\n",
    "    client_weights = []\n",
    "    for c in clients:\n",
    "        weights = np.array(c.model.get_weights())\n",
    "        client_weights.append(weights)\n",
    "    \n",
    "    # Calculate client weight scaling factor\n",
    "    scaling_factor_clients = []\n",
    "    for c in clients:\n",
    "        scaling_factor = len(c.data) / global_amount_data\n",
    "        scaling_factor_clients.append(scaling_factor)\n",
    "\n",
    "    # Construct new global model from client weights\n",
    "    new_global_weights = np.array(global_weights) * 0 # Create empty weights array \n",
    "    for scaling_factor, weights in zip(scaling_factor_clients, client_weights):\n",
    "        new_global_weights += weights * scaling_factor  \n",
    "\n",
    "    # Set the new weights on the global model\n",
    "    global_model.set_weights(new_global_weights)\n",
    "    acc = evaluate_model(global_model, X_test, y_test)\n",
    "    \n",
    "    nr_cycles += 1\n",
    "    print(\"Cycle \", nr_cycles, \" complete. Global model accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78db9aa",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a7af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7342c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model():\n",
    "    model = Sequential(name=\"MNIST_Classifier\")\n",
    "    model.add(Dense(784, input_shape = (784,), activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer='adam'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2143514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_to_data(model, X, y, n_classes, epochs):\n",
    "    y_one_hot = to_categorical(y, n_classes)\n",
    "    model.fit(\n",
    "        X, # Samples\n",
    "        y_one_hot, # Labels\n",
    "        batch_size=32,\n",
    "        epochs=epochs,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    one_hot_predictions = model.predict(X_test)\n",
    "    label_predictions = np.argmax(one_hot_predictions, axis=1)\n",
    "    return f1_score(y_test, label_predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b02862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_array(array, distribution):\n",
    "    distribution = np.array(distribution) * len(array)\n",
    "    distribution = [int(d) for d in distribution]\n",
    "    \n",
    "    it = iter(array)\n",
    "    return [np.array(list(islice(it, 0, i))) for i in distribution]\n",
    "\n",
    "def chunk_data(data, labels, distribution):\n",
    "    data_chunks = chunk_array(data, distribution)\n",
    "    label_chunks = chunk_array(labels, distribution)\n",
    "    return list(zip(data_chunks, label_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca00e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(data, labels, distribution):\n",
    "    # Split the training data into chunks with the provided distribution\n",
    "    client_data = chunk_data(X_train, y_train, distribution)\n",
    "    clients = []\n",
    "\n",
    "    # Create client instances, with data and temporary ML model\n",
    "    for c_d in client_data:\n",
    "\n",
    "        # Give a client its portion of data\n",
    "        new_client = Client(c_d[0], c_d[1])\n",
    "\n",
    "        # Create a simple model for each client \n",
    "        # This will be updated with the weights from global in the future\n",
    "        new_client.model = create_simple_model()\n",
    "\n",
    "        clients.append(new_client)\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad48596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_client_data(clients):\n",
    "    f, axs = plt.subplots(1,2,figsize=(12, 7))\n",
    "    for i in range(len(clients)):\n",
    "        labels = clients[i].labels\n",
    "\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.title('Owner {}'.format(i+1))\n",
    "        plt.ylim([0, 4500])\n",
    "        plt.xlim([-1,10])\n",
    "        plt.ylabel(\" \")\n",
    "        plt.yticks([])\n",
    "        plt.xticks(list(np.arange(0,10)))\n",
    "        sns.histplot(labels, bins=10, discrete=True)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=0.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
